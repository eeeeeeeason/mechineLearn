### knn计算最佳超参数(网格搜索)
- 基本实现逻辑
```
best_p = -1
best_score = 0.0
best_k = -1

for k in range(1,11):
    for p in range(1,6):
        knn_clf = KNeighborsClassifier(n_neighbors=k, weights="distance", p=p)
        knn_clf.fit(X_train, y_train)
        score = knn_clf.score(X_test, y_test)
        if score > best_score:
            best_k = k
            best_score = score
            best_p = p
            
print("best_p = " , best_p)
print("best_k = ", besk_k)
print("best_score =", best_score)
```
- demo
```
"""导入数据"""
from sklearn.datasets import load_iris
iris = load_iris()
"""分割数据为测试集与训练集"""
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.1, random_state=666)
"""设置需要交叉验证比较的超参数，这里有weights是否根据距离设置权重,n_neighbors,p-明可夫斯基的距离计算公司"""
param_grid = [
  {
    'weights': ['uniform'],
    'n_neighbors': [i for i in range(1,11)]
  },
  {
    'weights': ['distance'],
    'n_neighbors': [i for i in range(1,11)],
    'p': [i for i in range(1,6)]
  }
]
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import GridSearchCV
knn_clf = KNeighborsClassifier()
"""这东西不知道是个啥。模型？"""
%time
grid_search = GridSearchCV(knn_clf,param_grid, n_jobs=-1, verbose=2)
grid_search.fit(X_train, y_train)
knn_clf = grid_search.best_estimator_
knn_clf.score(X_test, y_test)
grid_search.best_params_
```
