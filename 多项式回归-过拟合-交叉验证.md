### 多项式回归
- 实际情况下，存在线性关系的数据并不多存在，大部分都是非线性关系
- 在y = ax^2 + bx + c 中，可以把x^2做为一个新的特征w, y = aw + bx + c 仍为一个线性方程，且w与x有某种关系，称为多项式回归
- 多项式回归解决思路：添加一个特征x^2
```py
  X2 = np.hstack([X,X**2])
  X2.shape
  lin_reg2 = LinearRegression()
  lin_reg2.fit(X2,y)
  y_predict2 = lin_reg2.predict(X2)
  plt.scatter(x,y)
  plt.plot(np.sort(x), y_predict2[np.argsort(x)],color='r') ### 需要使用排序完毕后的数据
```
- pipeline分步计算
```py
  from sklearn.pipeline import Pipeline
  from sklearn.preprocessing import PolynomialFeatures
  from sklearn.preprocessing import StandardScaler

  poly_reg = Pipeline([
      ("poly", PolynomialFeatures(degree=2)),
      ("std_scaler",StandardScaler()), # 标准化
      ("lin_reg",LinearRegression())
  ])
  poly_reg.fit(X,y)
  y_predict = poly_reg.predict(X)
  plt.scatter(x,y)
  plt.plot(np.sort(x), y_predict2[np.argsort(x)],color='r')
```
- 过拟合，欠拟合
  - 在更多系数的情况下一定存在一条直线能够覆盖所有样本，但实际上这么做是否存在意义或者说是否真的准确。如果过度了我们称为过拟合否则为欠拟合
  - 过拟合：过多的表达了数据间的噪音关系
  - 欠拟合：不能完整的表达数据关系
  - 泛化能力：在拟合训练数据后处理测试数据是否能够拥有相当的拟合程度。标准是使用测试数据的mean_squared_error的大小，\
    虽然多项式PolynomialFeatures过程中，训练数据集的拟合程度越来越高，但最终是否合理需要用测试数据集进行判断
  - 学习曲线： 用于判断泛化能力。mse均方误差将训练y和预测y，测试y和测试预测y输入后绘制表格。找到最接近的且mse稳定后较小的
- 验证数据集，交叉验证（cross_val_score,grid_searchcv）
  - 验证数据集存在的原因：如果只存在简单的训练数据集与测试数据集，结果会导致模型过拟合测试数据集，因为模型的准确度由测试数据集决定了。
  - 交叉验证解决：将训练数据集分为k份（3），ABC，bc，ac,ab做训练，a,b,c做超参数的验证数据集，以平均结果为该参数的合理判断。最后再给测试数据集使用
- 偏差和方差
  - 非参数学习都是高方差算法，参数学习通常都是高偏差算法（模型有假设）
  - 机器学习主要挑战在方差，处理方案
    - 1 降低模型复杂度
    - 2 减少数据维度，降噪
    - 3 增加样本数
    - 4 使用验证集
- 岭回归正则化，LASSO回归：mse的theta最小
   
